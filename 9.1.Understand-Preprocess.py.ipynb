{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 9.1] preprocess.py 파일 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 preprocess.py 파일의 모듈(함수)가 어떻게 쓰이는지, 노트북 2.0, 3.0에서 사용한 Use Case 기준으로 정리 합니다.\n",
    "- (1) 전처리 모델 학습(Training Feature Transformer)\n",
    "- (2) 전처리 모델 배치 추론 (Inference Feature Transformer)\n",
    "- (3) Realtime Endpoint 추론 \n",
    "\n",
    "\n",
    "preprocess.py는 크게 아래 다섯개의 모듈(함수)로 구성 되어 있습니다.\n",
    "다섯개의 모듈이 위의 Use Case를 지원 합니다.\n",
    "\n",
    "\n",
    "- main() 함수\n",
    "```python\n",
    "    if __name__ == '__main__':\n",
    "```\n",
    "- input_fn(input_data, request_content_type)\n",
    "- model_fn(model_dir)\n",
    "- predict_fn(input_data, model)\n",
    "- output_fn(prediction, accept)\n",
    "\n",
    "Reference: <br>\n",
    "아래 블로그의 Step 4: Create preprocessing script 단락을 보시면 조금 더 설명이 있습니다. 참고 하세요.<br>\n",
    "Blog: [Preprocess input data before making predictions using Amazon SageMaker inference pipelines and Scikit-learn](https://aws.amazon.com/blogs/machine-learning/preprocess-input-data-before-making-predictions-using-amazon-sagemaker-inference-pipelines-and-scikit-learn/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 전처리 모델 학습(Training Feature Transformer)\n",
    "\n",
    "학습은 아래의 SKLearn Estimator의 fit()를 통해서 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path, # script_path: preprocess.py\n",
    "    role=role,\n",
    "    train_instance_type=\"local\")\n",
    "sklearn_preprocessor.fit({'train': s3_input_train})\n",
    "```\n",
    "위의 Estimator SKLearn.fit() 함수는 인스턴스를 뛰우고, sagemaker_sklearn_container 이미지를 다운로드 받습니다. <br>\n",
    "sagemaker_sklearn_container 에서는 아래 명령어를 실행 합니다. \n",
    "```python\n",
    "/miniconda3/bin/python -m preprocessing\n",
    "```\n",
    "위 명령어는 preprocessing.py 파일을 실행하기에 **main() 만을** 실행합니다.\n",
    "```\n",
    "if __name__ == '__main__':\n",
    "    ...\n",
    "    ...\n",
    "    preprocessor.fit(concat_data)\n",
    "    joblib.dump(preprocessor, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "    print(\"saved model!\")\n",
    "``` \n",
    "joblib.dump() 는 /opt/ml/model/model.joblib 에 저장을 하게 하고, 이 파일은 SageMaker의 의해서 S3로 업로드 하게 됩니다. (에: s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-08-08-02-58-52-731/output/model.tar.gz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 전처리 모델 배치 추론 (Inference Feature Transformer)\n",
    "\n",
    "위에서 학습을 한 전처리 모델을 가지고 Raw Train, Validation, Test 데이타를 제공하여 전처리 데이타(preprocessed data)를 만드는 과정 입니다. \n",
    "\n",
    "내부적으로 **input data (input_fn() 호출) --> 전처리모델.transform() (model_fn(), predict_fn() 호출)** 하여 전처리된 데이타가 생성이 됩니다. (<font color=\"red\">**output_fn()은 사용 안함**</font>)\n",
    "\n",
    "predict_fn() 는 전처리 모델 배치 추론의 컨테이너에 아래와 같이 환경 변수에 영향을 받습니다.\n",
    "model_fn(), input_fn() 는 아래 내용 참고 하세요\n",
    "```python\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model(\n",
    "    env={'TRANSFORM_MODE': 'feature-transform'})\n",
    "```\n",
    "위의 환경 변수로 인해서 아래 predict_fn() 안에서 _is_feature_transform() True이고 이에 해당하는 코드가 실행이 됩니다. features = model.transform(input_data) 가 실행 됩니다.\n",
    "\n",
    "```python\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Preprocess input data\n",
    "    \n",
    "    We implement this because the default predict_fn uses .predict(), but our model is a preprocessor\n",
    "    so we want to use .transform().\n",
    "\n",
    "    The output is returned in the following order:\n",
    "    \n",
    "        rest of features either one hot encoded or standardized\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if _is_feature_transform():\n",
    "        features = model.transform(input_data)\n",
    "\n",
    "\n",
    "        if label_column in input_data:\n",
    "            # Return the label (as the first column) and the set of features.\n",
    "            return np.insert(features.toarray(), 0, pd.get_dummies(input_data[label_column])['True.'], axis=1)\n",
    "        else:\n",
    "            # Return only the set of features\n",
    "            return features\n",
    "    \n",
    "    # 아래는 후처리에서 사용이 되고, 여기서는 사용을 하지 않습니다. \n",
    "    if _is_inverse_label_transform():\n",
    "        features = input_data.iloc[:,0]>0.5\n",
    "        features = features.values\n",
    "        return features\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model_fn(model_dir) 함수\n",
    "\n",
    "SageMaker는 model_dir 의 경로로 부터 모델을 리턴한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted model\n",
    "    \"\"\"\n",
    "    if _is_feature_transform():\n",
    "        preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "        return preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_fn(input_data, request_content_type) 함수\n",
    "\n",
    "input_fn 함수는 request_content_type로서 'text/csv'를 받게 되고, 입력 컬럼수에 따라서 컬럼 이름을 설정하여 dataframe을 리턴 합니다.\n",
    "\n",
    "```python\n",
    "def input_fn(input_data, request_content_type):\n",
    "    if _is_feature_transform():\n",
    "        if content_type == 'text/csv':\n",
    "            # Read the raw input data as CSV.\n",
    "            df = pd.read_csv(StringIO(input_data),  header=None)\n",
    "            if len(df.columns) == len(feature_columns_names) + 1:\n",
    "                # This is a labelled example, includes the  label\n",
    "                df.columns = feature_columns_names + [label_column]\n",
    "            elif len(df.columns) == len(feature_columns_names):\n",
    "                # This is an unlabelled example.\n",
    "                df.columns = feature_columns_names\n",
    "            return df\n",
    "        else:\n",
    "            raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "    \n",
    "    # 아래는 후처리에서 사용이 되고, 여기서는 사용을 하지 않습니다.     \n",
    "    if _is_inverse_label_transform():\n",
    "        if (content_type == 'text/csv' or content_type == 'text/csv; charset=utf-8'):\n",
    "            # Read the raw input data as CSV.\n",
    "            df = pd.read_csv(StringIO(str_buffer),  header=None)\n",
    "            logging.info(f\"Shape of the requested data: '{df.shape}'\")\n",
    "            return df\n",
    "        else:\n",
    "            raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Realtime Endpoint 추론 \n",
    "\n",
    "Inference Pipeline의 One model을 만들고 Endpoint를 생성 합니다.\n",
    "아래와 같이 instance를 제공하여 추론을 요청하면, 결과가 False로 나옵니다\n",
    "```\n",
    "instance: \n",
    " KS,186,510,400-6454,no,no,0,137.8,97,23.43,187.7,118,15.95,146.4,85,6.59,8.7,6,2.35,1\n",
    "Churn result?: \n",
    " b'False\\n'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 Realtime Endpoint에 위의 Instance 추론 요청을 하였고, 이후에 CloudWatch에서 로그를 확인 하였습니다.<br>\n",
    "\n",
    "- Container-1 (전처리)\n",
    "    - input_fn --> predict_fn --> output_fn 을 하였고, predict_fn에서는 model.transform(input_data)를 통하여 전치리를 하였습니다.\n",
    "- Container-2 (XGBoost)\n",
    "    - csv 입력값을 받아서, 모델에서 결과값을 제공 합니다.\n",
    "- Container-3 (후처리)\n",
    "    - input_fn --> predict_fn --> output_fn 으로 호출을 하며, predict_fn에서 XGBoost에서 받은 Score 값을 False 로 변환 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig9.1.inferenceflow](img/Fig9.1.inference_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output_fn(prediction, accept) 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"Format prediction output\n",
    "    \n",
    "    The default accept/content-type between containers for serial inference is JSON.\n",
    "    We also want to set the ContentType or mimetype as the same value as accept so the next\n",
    "    container can read the response payload correctly.\n",
    "    \"\"\"\n",
    "    \n",
    "    accept = 'text/csv'\n",
    "    if type(prediction) is not np.ndarray:\n",
    "        prediction=prediction.toarray()\n",
    "    \n",
    "   \n",
    "    if accept == \"application/json\":\n",
    "        instances = []\n",
    "        for row in prediction.tolist():\n",
    "            instances.append({\"features\": row})\n",
    "\n",
    "        json_output = {\"instances\": instances}\n",
    "\n",
    "        return worker.Response(json.dumps(json_output), mimetype=accept)\n",
    "    elif accept == 'text/csv':\n",
    "        return worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
    "    else:\n",
    "        raise RuntimeException(\"{} accept type is not supported by this \n",
    "        script.\".format(accept))\n",
    "```                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
