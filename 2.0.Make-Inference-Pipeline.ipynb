{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2.0] Inferencde Pipeline 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 노트북에서는 아래의 내용을 진행 합니다.\n",
    "    - Feature Transfomer(전처리 학습 모델) 생성\n",
    "    - Train 데이타를 Feature Transfomer를 통해서 전처리 데이타 생성\n",
    "    - Validation 데이타를 Feature Transfomer를 통해서 전처리 데이타 생성\n",
    "    - XGBoost를 학습\n",
    "    - Post-Processing Model 생성\n",
    "    - Inference Pipeline 생성\n",
    "- 소요 시간은 약 10분 걸립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer (전처리 학습 모델) - preprocessing.py 파일\n",
    "- Numerical 데이타는 <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html>StandardScaler</a>를 사용하여 Normalization을 함. \n",
    "    * z = (x - u) / s \n",
    "        * (z: 표준화된 값. 이 값을 학습시에 사용, x: 각 테이타의 값, u: 데이타 항목의 평균, s: 데이타 항목의 표준편차)\n",
    "- 아래 Account Length, ..CustServ Calls까지 모두 위의 방법으로 전처리 함.\n",
    "    - 아래 imputer는 결측값이 있을 경우에 해당 컬럼의 median 값을 사용 함.\n",
    "\n",
    "```python\n",
    "    numeric_features = list([\n",
    "    'Account Length',\n",
    "    'VMail Message',\n",
    "    'Day Mins',\n",
    "    'Day Calls',\n",
    "    'Eve Mins',\n",
    "    'Eve Calls',\n",
    "    'Night Mins',\n",
    "    'Night Calls',\n",
    "    'Intl Mins',\n",
    "    'Intl Calls',\n",
    "    'CustServ Calls'])\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "```\n",
    "- Categorical 데이타는 One Hot Encoding 방식으로 전처리 함. (예, 남자:0, 여자:1 일 경우에 남자:(1,0), 여자:(0,1) 방식으로 처리)\n",
    "    - State, Area Code, Int'l Plan, VMail Plan을 적용 함\n",
    "```python\n",
    "    categorical_features = ['State','Area Code',\"Int'l Plan\",'VMail Plan']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "```\n",
    "- 최종적으로 Numerical and Categorical Transformer를 합쳐서 Transformer 생성하고, 학습하여 Transformer의 모델을 S3에 업로드 함.\n",
    "```python\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder=\"drop\")\n",
    "\n",
    "    preprocessor.fit(concat_data)\n",
    "\n",
    "    joblib.dump(preprocessor, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "```\n",
    "- Phone 데이타 항목은 위의 전처리 항목에서 제외 함. 유저별로 고유한 번호이기에 피쳐로서 의미가 없을 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from time import strftime, gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer (전처리 학습 모델) 생성\n",
    "아래는 다음과 같은 작업을 합니다.\n",
    "- SKLearn 이라는 Estimator를 생성 합니다. \n",
    "    - s3_input_train의 학습 데이타를 SKLearn 입력으로 제공 합니다.\n",
    "    - \"전처리 학습 모델 (Featurizer)\" 을 생성할 수 있는 소스 코드 preprocessing.py 를 지정 합니다. \n",
    "    - 사용할 리소스로 instance_type = 'local' 를 지정 합니다. (이미 노트북 인스턴스에 설치된 Docker-compose를 이용 합니다.)\n",
    "        - **Local 이 아니라 SageMaker Cloud Instance도 사용 가능 합니다. (예: ml.m4.xlarge)**\n",
    "        - **아래 XGBoost 학습 알고리즘을 사용시에는 SageMaker Cloud Instance 사용함**\n",
    "- SKLearn의 \"전처리 학습 모델\"이 완료가 되면 결과인 모델 아티펙트 파일이 (model.tar.gz)  s3://{bucket_name}/{job_name}/output.tar.gz 에 저장 됩니다. \n",
    "    - (예: s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-15-08-39-41-035/model.tar.gz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래는 약 1분 정도가 소요 됩니다. 아래 셀의 [*] 의 표시가 [숫자] (에: [3])로 바뀔 때까지 기다려 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is not the latest supported version. If you would like to use version 0.23-1, please add framework_version=0.23-1 to your constructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmptrf96z4h_algo-1-ll7o5_1 ... \n",
      "\u001b[1BAttaching to tmptrf96z4h_algo-1-ll7o5_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,682 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,684 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,696 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,829 sagemaker-containers INFO     Module preprocessing does not provide a setup.py. \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,829 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,830 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:11,830 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=9703 sha256=b6c0e220aecc394c9e79e9a909607ab09f786b96251fab6824fadcdf9364b4fb\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-vktfm8k4/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:13,056 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:13,070 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"current_host\": \"algo-1-ll7o5\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         \"algo-1-ll7o5\"\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m             \"ContentType\": \"csv\"\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2020-08-03-07-35-08-986\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"master_hostname\": \"algo-1-ll7o5\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-west-2-311515152513/sagemaker-scikit-learn-2020-08-03-07-35-08-986/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"module_name\": \"preprocessing\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         \"current_host\": \"algo-1-ll7o5\",\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m             \"algo-1-ll7o5\"\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m     \"user_entry_point\": \"preprocessing.py\"\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_HOSTS=[\"algo-1-ll7o5\"]\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_USER_ENTRY_POINT=preprocessing.py\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ll7o5\",\"hosts\":[\"algo-1-ll7o5\"]}\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_CURRENT_HOST=algo-1-ll7o5\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_MODULE_NAME=preprocessing\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-west-2-311515152513/sagemaker-scikit-learn-2020-08-03-07-35-08-986/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-ll7o5\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-ll7o5\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-08-03-07-35-08-986\",\"log_level\":20,\"master_hostname\":\"algo-1-ll7o5\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-311515152513/sagemaker-scikit-learn-2020-08-03-07-35-08-986/source/sourcedir.tar.gz\",\"module_name\":\"preprocessing\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ll7o5\",\"hosts\":[\"algo-1-ll7o5\"]},\"user_entry_point\":\"preprocessing.py\"}\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m PYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m /miniconda3/bin/python -m preprocessing\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m saved model!\n",
      "\u001b[36malgo-1-ll7o5_1  |\u001b[0m 2020-08-03 07:35:14,183 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmptrf96z4h_algo-1-ll7o5_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "sagemaker_session = sagemaker.Session()\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "script_path = 'preprocessing.py'\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    role=role,\n",
    "    train_instance_type=\"local\")\n",
    "sklearn_preprocessor.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transfomer를 사용하여 전처리된 학습 및 검증 데이타 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Transformer_Train](img/Fig2.1.transformer_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Training data (Feature) 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래는 약 1분 정도가 소요 됩니다. 아래 셀의 [*] 의 표시가 [숫자] (에: [4])로 바뀔 때까지 기다려 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmp8vc1wc0x_algo-1-25aeq_1\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=9703 sha256=2ef8f006f310e4cdbc0fbc8d44ad10868a475acef7634f61ee4bc7c7086789f3\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-3kjhqw_g/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:18 +0000] [37] [INFO] Starting gunicorn 19.9.0\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:18 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:18 +0000] [37] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:18 +0000] [40] [INFO] Booting worker with pid: 40\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:18 +0000] [41] [INFO] Booting worker with pid: 41\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:18 +0000] [45] [INFO] Booting worker with pid: 45\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m [2020-08-03 07:35:19 +0000] [46] [INFO] Booting worker with pid: 46\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m 2020-08-03 07:35:19,977 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m 172.18.0.1 - - [03/Aug/2020:07:35:20 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m 2020-08-03 07:35:20,438 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m 172.18.0.1 - - [03/Aug/2020:07:35:20 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"-\"\n",
      "\u001b[36malgo-1-25aeq_1  |\u001b[0m 172.18.0.1 - - [03/Aug/2020:07:35:21 +0000] \"POST /invocations HTTP/1.1\" 200 1054525 \"-\" \"-\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Waiting for transform job: sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-14-797\n",
      ".s3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-14-797\n"
     ]
    }
   ],
   "source": [
    "# 아웃풋 경로 지정\n",
    "transform_train_output_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-train-output')\n",
    "instance_type = 'local'\n",
    "\n",
    "# scikit_learn_inferencee_model 이름으로 전처리 학습 모델 생성\n",
    "# TRANSFORM_MODE의 환경 변수는 전처리 모드라는 것을 알려 줌.\n",
    "    # 추론시에는 환경 변수를 TRANSFORM_MODE\": \"inverse-label-transform\" 설정 함.\n",
    "    # 위의 두개의 과정을 분리할 수 있으나, 한개의 소스를 (preprocessor.py)를 사용하기 위해서, 환경 변수를 통해서 구분함.\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model(\n",
    "    env={'TRANSFORM_MODE': 'feature-transform'})\n",
    "# scikit_learn_inferencee_model 에서 Train Transformer 생성\n",
    "transformer_train = scikit_learn_inferencee_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type= instance_type,\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_train_output_path,\n",
    "    accept = 'text/csv')\n",
    "\n",
    "\n",
    "# Preprocess training input\n",
    "transformer_train.transform(s3_input_train.config['DataSource']['S3DataSource']['S3Uri'], \n",
    "                            content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer_train.latest_transform_job.job_name)\n",
    "transformer_train.wait()\n",
    "preprocessed_train_path = transformer_train.output_path + transformer_train.latest_transform_job.job_name\n",
    "print(preprocessed_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training 전처리된 학습 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-14-797\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-03 07:35:22    1054526 sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-14-797/train.csv.out\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {preprocessed_train_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.11941369588439606</th>\n",
       "      <th>-0.5962380254245051</th>\n",
       "      <th>1.744368057672484</th>\n",
       "      <th>0.9789570533336895</th>\n",
       "      <th>-0.028992907038264654</th>\n",
       "      <th>-0.8931854019845896</th>\n",
       "      <th>-0.8017032037830547</th>\n",
       "      <th>-1.9825286353116254</th>\n",
       "      <th>-1.5305589315744583</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0.48</th>\n",
       "      <th>0.0.49</th>\n",
       "      <th>0.0.50</th>\n",
       "      <th>0.0.51</th>\n",
       "      <th>0.0.52</th>\n",
       "      <th>0.0.53</th>\n",
       "      <th>1.0.1</th>\n",
       "      <th>0.0.54</th>\n",
       "      <th>1.0.2</th>\n",
       "      <th>0.0.55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.852652</td>\n",
       "      <td>-0.596238</td>\n",
       "      <td>0.140284</td>\n",
       "      <td>-0.310405</td>\n",
       "      <td>0.970689</td>\n",
       "      <td>-0.689888</td>\n",
       "      <td>0.146389</td>\n",
       "      <td>1.232901</td>\n",
       "      <td>0.124852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.181295</td>\n",
       "      <td>-0.596238</td>\n",
       "      <td>1.835130</td>\n",
       "      <td>0.185503</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>-0.639063</td>\n",
       "      <td>1.568529</td>\n",
       "      <td>-0.063643</td>\n",
       "      <td>-0.846802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776769</td>\n",
       "      <td>-0.596238</td>\n",
       "      <td>0.216227</td>\n",
       "      <td>0.334276</td>\n",
       "      <td>0.136954</td>\n",
       "      <td>1.393914</td>\n",
       "      <td>1.394712</td>\n",
       "      <td>-0.634123</td>\n",
       "      <td>0.844596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.234547</td>\n",
       "      <td>1.508734</td>\n",
       "      <td>-0.459859</td>\n",
       "      <td>0.483049</td>\n",
       "      <td>-0.230929</td>\n",
       "      <td>0.224952</td>\n",
       "      <td>1.056954</td>\n",
       "      <td>0.921730</td>\n",
       "      <td>-0.810815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751486</td>\n",
       "      <td>1.218393</td>\n",
       "      <td>0.231046</td>\n",
       "      <td>-0.756723</td>\n",
       "      <td>0.516833</td>\n",
       "      <td>0.275776</td>\n",
       "      <td>1.043127</td>\n",
       "      <td>-2.138114</td>\n",
       "      <td>0.232814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  0.11941369588439606  -0.5962380254245051  1.744368057672484  \\\n",
       "0  0.0            -1.852652            -0.596238           0.140284   \n",
       "1  1.0             1.181295            -0.596238           1.835130   \n",
       "2  0.0             0.776769            -0.596238           0.216227   \n",
       "3  0.0            -0.234547             1.508734          -0.459859   \n",
       "4  0.0             0.751486             1.218393           0.231046   \n",
       "\n",
       "   0.9789570533336895  -0.028992907038264654  -0.8931854019845896  \\\n",
       "0           -0.310405               0.970689            -0.689888   \n",
       "1            0.185503               0.030988            -0.639063   \n",
       "2            0.334276               0.136954             1.393914   \n",
       "3            0.483049              -0.230929             0.224952   \n",
       "4           -0.756723               0.516833             0.275776   \n",
       "\n",
       "   -0.8017032037830547  -1.9825286353116254  -1.5305589315744583  ...  0.0.48  \\\n",
       "0             0.146389             1.232901             0.124852  ...     0.0   \n",
       "1             1.568529            -0.063643            -0.846802  ...     0.0   \n",
       "2             1.394712            -0.634123             0.844596  ...     0.0   \n",
       "3             1.056954             0.921730            -0.810815  ...     0.0   \n",
       "4             1.043127            -2.138114             0.232814  ...     0.0   \n",
       "\n",
       "   0.0.49  0.0.50  0.0.51  0.0.52  0.0.53  1.0.1  0.0.54  1.0.2  0.0.55  \n",
       "0     0.0     1.0     0.0     0.0     0.0    1.0     0.0    1.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0    1.0     0.0    1.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0    1.0     0.0    1.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0    1.0     0.0    0.0     1.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0    1.0     0.0    0.0     1.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_path_file = os.path.join (preprocessed_train_path, 'train.csv.out')\n",
    "df_pre_train = pd.read_csv(preprocessed_train_path_file)\n",
    "df_pre_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessed Validation data (Feature) 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래는 약 1분 정도가 소요 됩니다. 아래 셀의 [*] 의 표시가 [숫자] (에: [8])로 바뀔 때까지 기다려 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpnvn1og3t_algo-1-ydv4q_1\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=9703 sha256=00030e2cd170362afdaf7719450dc9e78017e53b0cb773bd5327ac35eb8fae86\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-5nydqxdg/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [37] [INFO] Starting gunicorn 19.9.0\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [37] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [40] [INFO] Booting worker with pid: 40\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [44] [INFO] Booting worker with pid: 44\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [45] [INFO] Booting worker with pid: 45\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m [2020-08-03 07:35:27 +0000] [46] [INFO] Booting worker with pid: 46\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m 2020-08-03 07:35:28,325 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m 172.18.0.1 - - [03/Aug/2020:07:35:28 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m 2020-08-03 07:35:28,817 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m 172.18.0.1 - - [03/Aug/2020:07:35:29 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"-\"\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m 2020-08-03 07:35:29,466 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-ydv4q_1  |\u001b[0m 172.18.0.1 - - [03/Aug/2020:07:35:30 +0000] \"POST /invocations HTTP/1.1\" 200 300974 \"-\" \"-\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Waiting for transform job: sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-23-157\n",
      ".s3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-23-157\n"
     ]
    }
   ],
   "source": [
    "# 아웃풋 경로 지정\n",
    "transform_validation_output_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-validation-output')\n",
    "# scikit_learn_inferencee_model 에서 Validation Transformer 생성\n",
    "transformer_validation = scikit_learn_inferencee_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type= instance_type,\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_validation_output_path,\n",
    "    accept = 'text/csv')\n",
    "# Preprocess validation input\n",
    "transformer_validation.transform(s3_input_validation.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer_validation.latest_transform_job.job_name)\n",
    "transformer_validation.wait()\n",
    "preprocessed_validation_path = transformer_validation.output_path+transformer_validation.latest_transform_job.job_name\n",
    "print(preprocessed_validation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-23-157'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_validation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-03 07:35:31     300975 sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-23-157/validation.csv.out\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {preprocessed_validation_path} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train with XGBoost on SageMaker Cloud Instance\n",
    "아 과정은 위의 전처리된 데이타를 가지고 실제 SageMaker Built-in Algorithm XGBoost를 이용하여 학습을 수행 합니다.<br>\n",
    "실제의 학습 과정은 SageMaker Cloud Instance에서 실제 학습니 됩니다.\n",
    "\n",
    "\n",
    "Built-in XGboost 알고리즘 컨테이너를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '1.0-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3에 있는 Train, Validation 전처리된 (Features) 데이타의 경로 및 파일 포맷등을 지정하는 오브젝트를 생성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Train input: \n",
      "\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-14-797', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "\n",
      "S3 Validation input: \n",
      "\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-08-03-07-35-2020-08-03-07-35-23-157', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "s3_input_train_processed = sagemaker.session.s3_input(\n",
    "    preprocessed_train_path, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(\"S3 Train input: \\n\")\n",
    "print(s3_input_train_processed.config)\n",
    "s3_input_validation_processed = sagemaker.session.s3_input(\n",
    "    preprocessed_validation_path, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(\"\\nS3 Validation input: \\n\")\n",
    "print(s3_input_validation_processed.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 중요한 XGBoost의 [하이퍼파라미터](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html) 입니다. 아래 내용 참고 하세요.\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래는 약 5분 정도가 소요 됩니다. 아래 셀의 [*] 의 표시가 [숫자] (에: [13])로 바뀔 때까지 기다려 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-03 07:35:32 Starting - Starting the training job...\n",
      "2020-08-03 07:35:33 Starting - Launching requested ML instances......\n",
      "2020-08-03 07:36:43 Starting - Preparing the instances for training...\n",
      "2020-08-03 07:37:32 Downloading - Downloading input data...\n",
      "2020-08-03 07:37:50 Training - Downloading the training image...\n",
      "2020-08-03 07:38:33 Uploading - Uploading generated training model.\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:38:29] 2333x69 matrix with 160977 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[07:38:29] 666x69 matrix with 45954 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 2333 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 666 rows\u001b[0m\n",
      "\u001b[34m[07:38:29] WARNING: /workspace/src/learner.cc:328: \u001b[0m\n",
      "\u001b[34mParameters: { num_round, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.07715#011validation-error:0.09910\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.05058#011validation-error:0.08108\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.04886#011validation-error:0.07508\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.04672#011validation-error:0.07207\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.04801#011validation-error:0.07357\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.04672#011validation-error:0.07057\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.04544#011validation-error:0.07357\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.04372#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.04501#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.04244#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.04029#011validation-error:0.06456\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.03901#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.03858#011validation-error:0.06456\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.03772#011validation-error:0.06456\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.03772#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.03943#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.03858#011validation-error:0.06306\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.03772#011validation-error:0.06456\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.03943#011validation-error:0.06306\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.03986#011validation-error:0.06006\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.03943#011validation-error:0.06306\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.03858#011validation-error:0.06306\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.03815#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.03686#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.03601#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.03429#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.03386#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.03386#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.03386#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.03386#011validation-error:0.07207\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.03386#011validation-error:0.07057\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.03429#011validation-error:0.07207\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.03472#011validation-error:0.07057\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.03472#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.03300#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.03386#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.03386#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.03300#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.03343#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.03300#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.03172#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.03172#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.03086#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.03129#011validation-error:0.06907\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.03086#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.03129#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.03086#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.03086#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.03043#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.03000#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.03000#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.03000#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.03000#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.03000#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.03000#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.03043#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.02915#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.02915#011validation-error:0.06757\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.02872#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.02915#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.02958#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.03000#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.02958#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.02786#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.02829#011validation-error:0.06607\u001b[0m\n",
      "\n",
      "2020-08-03 07:38:40 Completed - Training job completed\n",
      "Training seconds: 68\n",
      "Billable seconds: 68\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container, # Built-in XGBoost Container\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train_processed, 'validation': s3_input_validation_processed}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "- XGBoost에서 나온 결과 값( 0 <= Score <=1) 을 0.5 이하이면 False, 이상이면 True로 변환 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# sklearn_preprocessor 로 부터 후처리 모델을 생성 함.(scikit_learn_post_process_model)\n",
    "# 다만 환경 변수를 바꾸어 후처리용으로 사용 함 ()'TRANSFORM_MODE': 'inverse-label-transform')\n",
    "transform_postprocessor_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-postprocessing-output')\n",
    "scikit_learn_post_process_model = sklearn_preprocessor.create_model(env={'TRANSFORM_MODE': 'inverse-label-transform'})\n",
    "transformer_post_processing = scikit_learn_post_process_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='local',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_postprocessor_path,\n",
    "    accept = 'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline <a class=\"anchor\" id=\"pipeline_setup\"></a>\n",
    "\n",
    "아래 그림과 같이 위에서 생성한 전처리, 알고리즘 학습, 후처리의 세가지 모델을 가지고 1개의 단일 모델을 만들어 Inference Pipleline을 생성 합니다. <br>\n",
    "**입력 데이타 가공이 없이 실제 데이타가 입력이 되면, 1개의 단일 모델을 통해서 최종적으로 예측 결과인 True, False의 결과 값이 제공 됩니다.**\n",
    "\n",
    "![Inference-pipeline](img/Fig2.2.inference_pipeline.png)\n",
    "\n",
    "\n",
    "**Machine Learning Model Pipeline (Inference Pipeline)는 create_model() 를 호출하여 만들 수 있습니다.** <br>\n",
    "예를 들어 여기서는 the fitted Scikit-learn inference model, the fitted Xgboost model and the psotprocessing model 의 세가지 모델을 가지고 만듦니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 세개 모델의 위치를 확인 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Transformer Model:\n",
      " s3://sagemaker-us-west-2-311515152513/sagemaker-scikit-learn-2020-08-03-07-35-08-986/model.tar.gz\n",
      "\n",
      "XGBoost Model:\n",
      " s3://sagemaker-us-west-2-311515152513/sagemaker/customer-churn/output/sagemaker-xgboost-2020-08-03-07-35-32-030/output/model.tar.gz\n",
      "\n",
      "Post-Processing Model :\n",
      " s3://sagemaker-us-west-2-311515152513/sagemaker-scikit-learn-2020-08-03-07-35-08-986/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Transformer Model:\\n {}\".format(sklearn_preprocessor.model_data))\n",
    "print(\"\\nXGBoost Model:\\n {}\".format(xgb.model_data))\n",
    "print(\"\\nPost-Processing Model :\\n {}\".format(scikit_learn_post_process_model.model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3개의 모델을 연결하여 One Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'churn-inference-pipeline-2020-08-03-07-39-14'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_name = 'churn-inference-pipeline-' + timestamp_prefix\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            'Image': sklearn_preprocessor.image_name,\n",
    "            'ModelDataUrl': sklearn_preprocessor.model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": str(sklearn_preprocessor.enable_cloudwatch_metrics),\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": sklearn_preprocessor.uploaded_code.s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"feature-transform\",\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": str(sklearn_preprocessor.container_log_level),\n",
    "                    \"SAGEMAKER_REGION\": sklearn_preprocessor.sagemaker_session.boto_region_name,\n",
    "                    \"SAGEMAKER_PROGRAM\": sklearn_preprocessor.uploaded_code.script_name\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            'Image': xgb.image_name,\n",
    "            'ModelDataUrl': xgb.model_data,\n",
    "            \"Environment\": {}\n",
    "        },\n",
    "        {\n",
    "            'Image': scikit_learn_post_process_model.image,\n",
    "            'ModelDataUrl': scikit_learn_post_process_model.model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": str(sklearn_preprocessor.enable_cloudwatch_metrics),\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": sklearn_preprocessor.uploaded_code.s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"inverse-label-transform\",\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": str(sklearn_preprocessor.container_log_level),\n",
    "                    \"SAGEMAKER_REGION\": sklearn_preprocessor.sagemaker_session.boto_region_name,\n",
    "                    \"SAGEMAKER_PROGRAM\": sklearn_preprocessor.uploaded_code.script_name\n",
    "                }\n",
    "        },\n",
    "    ],\n",
    "    ExecutionRoleArn = role,\n",
    ")\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 Inference Pipeline의 모델을 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference pipeline model name:\n",
      " churn-inference-pipeline-2020-08-03-07-39-14\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference pipeline model name:\\n {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
