{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2.0] Inferencde Pipeline 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 노트북에서는 아래의 내용을 진행 합니다.\n",
    "    - Feature Transfomer(전처리 학습 모델) 생성\n",
    "    - Train 데이타를 Feature Transfomer를 통해서 전처리 데이타 생성\n",
    "    - Validation 데이타를 Feature Transfomer를 통해서 전처리 데이타 생성\n",
    "    - XGBoost를 학습\n",
    "    - Post-Processing Model 생성\n",
    "    - Inference Pipeline 생성\n",
    "- 소요 시간은 약 10분 걸립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer (전처리 학습 모델) - preprocessing.py 파일\n",
    "- Numerical 데이타는 <a href=https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html>StandardScaler</a>를 사용하여 Normalization을 함. \n",
    "    * z = (x - u) / s \n",
    "        * (z: 표준화된 값. 이 값을 학습시에 사용, x: 각 테이타의 값, u: 데이타 항목의 평균, s: 데이타 항목의 평균편차)\n",
    "- 아래 Account Length, ..CustServ Calls까지 모두 위의 방법으로 전처리 함.\n",
    "\n",
    "```python\n",
    "    numeric_features = list([\n",
    "    'Account Length',\n",
    "    'VMail Message',\n",
    "    'Day Mins',\n",
    "    'Day Calls',\n",
    "    'Eve Mins',\n",
    "    'Eve Calls',\n",
    "    'Night Mins',\n",
    "    'Night Calls',\n",
    "    'Intl Mins',\n",
    "    'Intl Calls',\n",
    "    'CustServ Calls'])\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "```\n",
    "- Categorical 데이타는 One Hot Encoding 방식으로 전처리 함.\n",
    "    - State, Area Code, Int'l Plan, VMail Plan을 적용 함\n",
    "```python\n",
    "    categorical_features = ['State','Area Code',\"Int'l Plan\",'VMail Plan']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "```\n",
    "- 최종적으로 Numerical and Categorical Transformer를 합쳐서 Transformer 생성하고, 학습하여 Transformer의 모델을 S3에 업로드 함.\n",
    "```python\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)],\n",
    "        remainder=\"drop\")\n",
    "\n",
    "    preprocessor.fit(concat_data)\n",
    "\n",
    "    joblib.dump(preprocessor, os.path.join(args.model_dir, \"model.joblib\"))\n",
    "```\n",
    "- Phone 데이타 항목은 위의 전처리 항목에서 제외 함. 유저별로 고유한 번호이기에 피쳐로서 의미가 없을 것으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from time import strftime, gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to restore variable 'sklearn_preprocessor', ignoring (use %store -d to forget!)\n",
      "The error was: <class 'KeyError'>\n"
     ]
    }
   ],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformer (전처리 학습 모델) 생성\n",
    "아래는 다음과 같은 작업을 합니다.\n",
    "- SKLearn 이라는 Estimator를 생성 합니다. \n",
    "    - s3_input_train의 학습 데이타를 SKLearn 입력으로 제공 합니다.\n",
    "    - \"전처리 학습 모델 (Featurizer)\" 을 생성할 수 있는 소스 코드를 preprocessing.py 지정 합니다. \n",
    "    - 사용할 리소스로 instance_type = 'local' 를 지정 합니다. (이미 노트북 인스턴스에 설치된 Docker-compose를 이용 합니다.)\n",
    "        - Local 이 아니라 SageMaker Cloud Instance도 사용 가능 합니다. (예: ml.m4.xlarge)\n",
    "- SKLearn의 \"전처리 학습 모델\"이 완료가 되면 결과인 모델 아티펙트인 (model.tar.gz) 파일이  s3://{bucket_name}/{job_name}/output.tar.gz 에 저장 됩니다. \n",
    "    - (예: s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-15-08-39-41-035/model.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpaatp0cdr_algo-1-2a0b0_1 ... \n",
      "\u001b[1BAttaching to tmpaatp0cdr_algo-1-2a0b0_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,378 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,380 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,389 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,514 sagemaker-containers INFO     Module preprocessing does not provide a setup.py. \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,514 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,514 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:33,514 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m /miniconda3/bin/python -m pip install . \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=9702 sha256=859506fdefa7e4ffa1667a6f210c21b93ce8ddd8205b22162c95085146256610\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-4aqbwp4z/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:34,427 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:34,436 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\"\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"current_host\": \"algo-1-2a0b0\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         \"algo-1-2a0b0\"\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"hyperparameters\": {},\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m             \"TrainingInputMode\": \"File\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m             \"ContentType\": \"csv\"\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"job_name\": \"sagemaker-scikit-learn-2020-07-19-01-59-31-329\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"master_hostname\": \"algo-1-2a0b0\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-19-01-59-31-329/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"module_name\": \"preprocessing\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"num_cpus\": 16,\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         \"current_host\": \"algo-1-2a0b0\",\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m             \"algo-1-2a0b0\"\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m     \"user_entry_point\": \"preprocessing.py\"\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_HOSTS=[\"algo-1-2a0b0\"]\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_HPS={}\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_USER_ENTRY_POINT=preprocessing.py\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-2a0b0\",\"hosts\":[\"algo-1-2a0b0\"]}\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_CHANNELS=[\"train\"]\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_CURRENT_HOST=algo-1-2a0b0\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_MODULE_NAME=preprocessing\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_NUM_CPUS=16\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-19-01-59-31-329/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-2a0b0\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-2a0b0\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-07-19-01-59-31-329\",\"log_level\":20,\"master_hostname\":\"algo-1-2a0b0\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-19-01-59-31-329/source/sourcedir.tar.gz\",\"module_name\":\"preprocessing\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-2a0b0\",\"hosts\":[\"algo-1-2a0b0\"]},\"user_entry_point\":\"preprocessing.py\"}\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_USER_ARGS=[]\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m PYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m /miniconda3/bin/python -m preprocessing\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m \n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m saved model!\n",
      "\u001b[36malgo-1-2a0b0_1  |\u001b[0m 2020-07-19 01:59:35,282 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36mtmpaatp0cdr_algo-1-2a0b0_1 exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "sagemaker_session = sagemaker.Session()\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "script_path = 'preprocessing.py'\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    role=role,\n",
    "    train_instance_type=\"local\")\n",
    "sklearn_preprocessor.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transfomer를 사용하여 전처리된 학습 및 검증 데이타 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Transformer_Train](img/Fig2.1.transformer_train.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessed Training data (Feature) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpfhwps_sm_algo-1-66tkn_1\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=9700 sha256=dc5002d37b088573e536d00abaaa1aa58d5db880c1bd116202dccaf715a50d0a\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-1wdr2csn/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [73] [INFO] Starting gunicorn 19.9.0\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [73] [INFO] Listening at: unix:/tmp/gunicorn.sock (73)\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [73] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [76] [INFO] Booting worker with pid: 76\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [92] [INFO] Booting worker with pid: 92\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [93] [INFO] Booting worker with pid: 93\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [124] [INFO] Booting worker with pid: 124\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [140] [INFO] Booting worker with pid: 140\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [141] [INFO] Booting worker with pid: 141\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [172] [INFO] Booting worker with pid: 172\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [174] [INFO] Booting worker with pid: 174\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [175] [INFO] Booting worker with pid: 175\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [176] [INFO] Booting worker with pid: 176\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [207] [INFO] Booting worker with pid: 207\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [224] [INFO] Booting worker with pid: 224\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [240] [INFO] Booting worker with pid: 240\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [241] [INFO] Booting worker with pid: 241\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [258] [INFO] Booting worker with pid: 258\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m [2020-07-19 01:59:39 +0000] [290] [INFO] Booting worker with pid: 290\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m 2020-07-19 01:59:41,060 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m 172.18.0.1 - - [19/Jul/2020:01:59:41 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m 172.18.0.1 - - [19/Jul/2020:01:59:41 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"-\"\n",
      "\u001b[36malgo-1-66tkn_1  |\u001b[0m 172.18.0.1 - - [19/Jul/2020:01:59:41 +0000] \"POST /invocations HTTP/1.1\" 200 1054525 \"-\" \"-\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Waiting for transform job: sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-35-904\n",
      ".s3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-35-904\n"
     ]
    }
   ],
   "source": [
    "# 아웃풋 경로 지정\n",
    "transform_train_output_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-train-output')\n",
    "instance_type = 'local'\n",
    "\n",
    "# scikit_learn_inferencee_model 이름으로 전처리 학습 모델 생성\n",
    "# TRANSFORM_MODE의 환경 변수는 전처리 모드라는 것을 알려 줌.\n",
    "    # 추론시에는 환경 변수를 TRANSFORM_MODE\": \"inverse-label-transform\" 설정 함.\n",
    "    # 위의 두개의 과정을 분리할 수 있으나, 한개의 소스를 (preprocessor.py)를 사용하기 위해서, 환경 변수를 통해서 구분함.\n",
    "scikit_learn_inferencee_model = sklearn_preprocessor.create_model(\n",
    "    env={'TRANSFORM_MODE': 'feature-transform'})\n",
    "# scikit_learn_inferencee_model 에서 Train Transformer 생성\n",
    "transformer_train = scikit_learn_inferencee_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type= instance_type,\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_train_output_path,\n",
    "    accept = 'text/csv')\n",
    "\n",
    "\n",
    "# Preprocess training input\n",
    "transformer_train.transform(s3_input_train.config['DataSource']['S3DataSource']['S3Uri'], \n",
    "                            content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer_train.latest_transform_job.job_name)\n",
    "transformer_train.wait()\n",
    "preprocessed_train_path = transformer_train.output_path + transformer_train.latest_transform_job.job_name\n",
    "print(preprocessed_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training 전처리된 학습 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-35-904\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-19 01:59:42    1054526 sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-35-904/train.csv.out\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {preprocessed_train_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.11941369588439606</th>\n",
       "      <th>-0.5962380254245051</th>\n",
       "      <th>1.744368057672484</th>\n",
       "      <th>0.9789570533336895</th>\n",
       "      <th>-0.028992907038264654</th>\n",
       "      <th>-0.8931854019845896</th>\n",
       "      <th>-0.8017032037830547</th>\n",
       "      <th>-1.9825286353116254</th>\n",
       "      <th>-1.5305589315744583</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0.48</th>\n",
       "      <th>0.0.49</th>\n",
       "      <th>0.0.50</th>\n",
       "      <th>0.0.51</th>\n",
       "      <th>0.0.52</th>\n",
       "      <th>0.0.53</th>\n",
       "      <th>1.0.1</th>\n",
       "      <th>0.0.54</th>\n",
       "      <th>1.0.2</th>\n",
       "      <th>0.0.55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.852652</td>\n",
       "      <td>-0.596238</td>\n",
       "      <td>0.140284</td>\n",
       "      <td>-0.310405</td>\n",
       "      <td>0.970689</td>\n",
       "      <td>-0.689888</td>\n",
       "      <td>0.146389</td>\n",
       "      <td>1.232901</td>\n",
       "      <td>0.124852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.181295</td>\n",
       "      <td>-0.596238</td>\n",
       "      <td>1.835130</td>\n",
       "      <td>0.185503</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>-0.639063</td>\n",
       "      <td>1.568529</td>\n",
       "      <td>-0.063643</td>\n",
       "      <td>-0.846802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.776769</td>\n",
       "      <td>-0.596238</td>\n",
       "      <td>0.216227</td>\n",
       "      <td>0.334276</td>\n",
       "      <td>0.136954</td>\n",
       "      <td>1.393914</td>\n",
       "      <td>1.394712</td>\n",
       "      <td>-0.634123</td>\n",
       "      <td>0.844596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.234547</td>\n",
       "      <td>1.508734</td>\n",
       "      <td>-0.459859</td>\n",
       "      <td>0.483049</td>\n",
       "      <td>-0.230929</td>\n",
       "      <td>0.224952</td>\n",
       "      <td>1.056954</td>\n",
       "      <td>0.921730</td>\n",
       "      <td>-0.810815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751486</td>\n",
       "      <td>1.218393</td>\n",
       "      <td>0.231046</td>\n",
       "      <td>-0.756723</td>\n",
       "      <td>0.516833</td>\n",
       "      <td>0.275776</td>\n",
       "      <td>1.043127</td>\n",
       "      <td>-2.138114</td>\n",
       "      <td>0.232814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  0.11941369588439606  -0.5962380254245051  1.744368057672484  \\\n",
       "0  0.0            -1.852652            -0.596238           0.140284   \n",
       "1  1.0             1.181295            -0.596238           1.835130   \n",
       "2  0.0             0.776769            -0.596238           0.216227   \n",
       "3  0.0            -0.234547             1.508734          -0.459859   \n",
       "4  0.0             0.751486             1.218393           0.231046   \n",
       "\n",
       "   0.9789570533336895  -0.028992907038264654  -0.8931854019845896  \\\n",
       "0           -0.310405               0.970689            -0.689888   \n",
       "1            0.185503               0.030988            -0.639063   \n",
       "2            0.334276               0.136954             1.393914   \n",
       "3            0.483049              -0.230929             0.224952   \n",
       "4           -0.756723               0.516833             0.275776   \n",
       "\n",
       "   -0.8017032037830547  -1.9825286353116254  -1.5305589315744583  ...  0.0.48  \\\n",
       "0             0.146389             1.232901             0.124852  ...     0.0   \n",
       "1             1.568529            -0.063643            -0.846802  ...     0.0   \n",
       "2             1.394712            -0.634123             0.844596  ...     0.0   \n",
       "3             1.056954             0.921730            -0.810815  ...     0.0   \n",
       "4             1.043127            -2.138114             0.232814  ...     0.0   \n",
       "\n",
       "   0.0.49  0.0.50  0.0.51  0.0.52  0.0.53  1.0.1  0.0.54  1.0.2  0.0.55  \n",
       "0     0.0     1.0     0.0     0.0     0.0    1.0     0.0    1.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0    1.0     0.0    1.0     0.0  \n",
       "2     0.0     0.0     0.0     0.0     0.0    1.0     0.0    1.0     0.0  \n",
       "3     0.0     0.0     0.0     0.0     0.0    1.0     0.0    0.0     1.0  \n",
       "4     0.0     0.0     0.0     0.0     0.0    1.0     0.0    0.0     1.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train_path_file = os.path.join (preprocessed_train_path, 'train.csv.out')\n",
    "df_pre_train = pd.read_csv(preprocessed_train_path_file)\n",
    "df_pre_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessed Validation data (Feature) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to tmpx7p1km_d_algo-1-1c0gy_1\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m Processing /opt/ml/code\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m Building wheels for collected packages: preprocessing\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m   Building wheel for preprocessing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m \u001b[?25h  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=9701 sha256=de867bcc809c8727d2acf7839f2f39832edc8725290a446359273fd5aa3e2f53\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-8e40e_q2/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m Successfully built preprocessing\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m Installing collected packages: preprocessing\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m Successfully installed preprocessing-1.0.0\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [72] [INFO] Starting gunicorn 19.9.0\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [72] [INFO] Listening at: unix:/tmp/gunicorn.sock (72)\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [72] [INFO] Using worker: gevent\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [75] [INFO] Booting worker with pid: 75\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [76] [INFO] Booting worker with pid: 76\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [107] [INFO] Booting worker with pid: 107\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [108] [INFO] Booting worker with pid: 108\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [109] [INFO] Booting worker with pid: 109\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [140] [INFO] Booting worker with pid: 140\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [141] [INFO] Booting worker with pid: 141\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [157] [INFO] Booting worker with pid: 157\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [173] [INFO] Booting worker with pid: 173\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [189] [INFO] Booting worker with pid: 189\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:46 +0000] [205] [INFO] Booting worker with pid: 205\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:47 +0000] [221] [INFO] Booting worker with pid: 221\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:47 +0000] [252] [INFO] Booting worker with pid: 252\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:47 +0000] [269] [INFO] Booting worker with pid: 269\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:47 +0000] [268] [INFO] Booting worker with pid: 268\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m [2020-07-19 01:59:47 +0000] [287] [INFO] Booting worker with pid: 287\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m 2020-07-19 01:59:48,451 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m /miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m   import imp\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m 172.18.0.1 - - [19/Jul/2020:01:59:48 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"-\"\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m 172.18.0.1 - - [19/Jul/2020:01:59:48 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"-\"\n",
      "\u001b[36malgo-1-1c0gy_1  |\u001b[0m 172.18.0.1 - - [19/Jul/2020:01:59:48 +0000] \"POST /invocations HTTP/1.1\" 200 300974 \"-\" \"-\"\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Waiting for transform job: sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-43-297\n",
      ".s3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-43-297\n"
     ]
    }
   ],
   "source": [
    "# 아웃풋 경로 지정\n",
    "transform_validation_output_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-validation-output')\n",
    "# scikit_learn_inferencee_model 에서 Validation Transformer 생성\n",
    "transformer_validation = scikit_learn_inferencee_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type= instance_type,\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_validation_output_path,\n",
    "    accept = 'text/csv')\n",
    "# Preprocess validation input\n",
    "transformer_validation.transform(s3_input_validation.config['DataSource']['S3DataSource']['S3Uri'], content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer_validation.latest_transform_job.job_name)\n",
    "transformer_validation.wait()\n",
    "preprocessed_validation_path = transformer_validation.output_path+transformer_validation.latest_transform_job.job_name\n",
    "print(preprocessed_validation_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-43-297'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_validation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-19 01:59:49     300975 sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-43-297/validation.csv.out\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {preprocessed_validation_path} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train with XGBoost\n",
    "Built-in XGboost 알고리즘 컨테이너를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='0.90-2'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '0.90-2').\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3에 있는 Train, Validation 전처리된 (Features) 데이타의 경로 및 파일 포맷등을 지정하는 오브젝트를 생성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/transformtrain-train-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-35-904', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/transformtrain-validation-output/sagemaker-scikit-learn-2020-07-19-01-59-2020-07-19-01-59-43-297', 'S3DataDistributionType': 'FullyReplicated'}}, 'ContentType': 'text/csv'}\n"
     ]
    }
   ],
   "source": [
    "s3_input_train_processed = sagemaker.session.s3_input(\n",
    "    preprocessed_train_path, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_train_processed.config)\n",
    "s3_input_validation_processed = sagemaker.session.s3_input(\n",
    "    preprocessed_validation_path, \n",
    "    distribution='FullyReplicated',\n",
    "    content_type='text/csv', \n",
    "    s3_data_type='S3Prefix')\n",
    "print(s3_input_validation_processed.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 중요한 XGBoost의 하이퍼파라미터 입니다. 아래 내용 참고 하세요.\n",
    "- `max_depth` controls how deep each tree within the algorithm can be built.  Deeper trees can lead to better fit, but are more computationally expensive and can lead to overfitting.  There is typically some trade-off in model performance that needs to be explored between a large number of shallow trees and a smaller number of deeper trees.\n",
    "- `subsample` controls sampling of the training data.  This technique can help reduce overfitting, but setting it too low can also starve the model of data.\n",
    "- `num_round` controls the number of boosting rounds.  This is essentially the subsequent models that are trained using the residuals of previous iterations.  Again, more rounds should produce a better fit on the training data, but can be computationally expensive or lead to overfitting.\n",
    "- `eta` controls how aggressive each round of boosting is.  Larger values lead to more conservative boosting.\n",
    "- `gamma` controls how aggressively trees are grown.  Larger values lead to more conservative models.\n",
    "\n",
    "More detail on XGBoost's hyperparmeters can be found on their GitHub [page](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-19 01:59:50 Starting - Starting the training job...\n",
      "2020-07-19 01:59:52 Starting - Launching requested ML instances.........\n",
      "2020-07-19 02:01:24 Starting - Preparing the instances for training...\n",
      "2020-07-19 02:02:20 Downloading - Downloading input data...\n",
      "2020-07-19 02:02:33 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-07-19:02:02:54:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-07-19:02:02:54:INFO] File size need to be processed in the node: 1.29mb. Available memory size in the node: 8488.67mb\u001b[0m\n",
      "\u001b[34m[2020-07-19:02:02:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[02:02:54] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[02:02:54] 2333x69 matrix with 160977 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-07-19:02:02:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[02:02:54] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[02:02:54] 666x69 matrix with 45954 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.058723#011validation-error:0.088589\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.051436#011validation-error:0.07958\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.045864#011validation-error:0.073574\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.046292#011validation-error:0.073574\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.047578#011validation-error:0.072072\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.045435#011validation-error:0.072072\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.045006#011validation-error:0.073574\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.043721#011validation-error:0.075075\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.042006#011validation-error:0.072072\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 16 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.041149#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.039006#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.038148#011validation-error:0.064565\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.039006#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.038577#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.037291#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.037291#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.036862#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.036434#011validation-error:0.064565\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.036005#011validation-error:0.064565\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.034291#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.034719#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.034291#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.034291#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.032576#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.032147#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.032147#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.031719#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.030862#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 14 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.031719#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.03129#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.03129#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 4 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.030433#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.030433#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.030862#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.030862#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.030862#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.029147#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.029147#011validation-error:0.064565\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.029147#011validation-error:0.064565\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.029576#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.029147#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.030004#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.02829#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.02829#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.02829#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.02829#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.02829#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.02829#011validation-error:0.070571\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.027432#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.027861#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.027432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.027432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.027004#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.027432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.027432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.027432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.027432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.026147#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.026147#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.026147#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 10 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.026147#011validation-error:0.069069\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 8 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.026147#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.026147#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.025289#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.024003#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.024003#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.024003#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.024003#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.024432#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.025289#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.025289#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.025289#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.025289#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.025289#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.024861#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.025289#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.024003#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.024003#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.025718#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.026147#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.026147#011validation-error:0.066066\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.025289#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.025289#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.025289#011validation-error:0.067568\u001b[0m\n",
      "\u001b[34m[02:02:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.024861#011validation-error:0.066066\u001b[0m\n",
      "\n",
      "2020-07-19 02:03:06 Uploading - Uploading generated training model\n",
      "2020-07-19 02:03:06 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 46\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container, # Built-in XGBoost Container\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        silent=0,\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=100)\n",
    "\n",
    "xgb.fit({'train': s3_input_train_processed, 'validation': s3_input_validation_processed}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "- XGBoost에서 나온 결과 값( 0 <= Score <=1) 을 0.5 이하이면 False, 이상이면 True로 변환 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_preprocessor 로 부터 후처리 모델을 생성 함.(scikit_learn_post_process_model)\n",
    "# 다만 환경 변수를 바꾸어 후처리용으로 사용 함 ()'TRANSFORM_MODE': 'inverse-label-transform')\n",
    "transform_postprocessor_path = 's3://{}/{}/{}/'.format(bucket, prefix, 'transformtrain-postprocessing-output')\n",
    "scikit_learn_post_process_model = sklearn_preprocessor.create_model(env={'TRANSFORM_MODE': 'inverse-label-transform'})\n",
    "transformer_post_processing = scikit_learn_post_process_model.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='local',\n",
    "    assemble_with = 'Line',\n",
    "    output_path = transform_postprocessor_path,\n",
    "    accept = 'text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Pipeline <a class=\"anchor\" id=\"pipeline_setup\"></a>\n",
    "\n",
    "![Inference-pipeline](img/Fig2.2.inference_pipeline.png)\n",
    "\n",
    "\n",
    "Machine Learning pipeline 는 create_model() 를 호출하여 만들 수 있습니다. 예를 들어 여기서는 the fitted Scikit-learn inference model, the fitted Xgboost model and the psotprocessing model 의 세가지 모델을 가지고 만듦니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 세개 모델의 위치를 확인 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Transformer Model:\n",
      " s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-19-01-59-31-329/model.tar.gz\n",
      "XGBoost Model:\n",
      " s3://sagemaker-us-east-2-057716757052/sagemaker/customer-churn/output/xgboost-2020-07-19-01-59-50-375/output/model.tar.gz\n",
      "Post-Processing Model :\n",
      " s3://sagemaker-us-east-2-057716757052/sagemaker-scikit-learn-2020-07-19-01-59-31-329/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Transformer Model:\\n {}\".format(sklearn_preprocessor.model_data))\n",
    "print(\"XGBoost Model:\\n {}\".format(xgb.model_data))\n",
    "print(\"Post-Processing Model :\\n {}\".format(scikit_learn_post_process_model.model_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'churn-inference-pipeline-2020-07-19-02-04-24'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model_name = 'churn-inference-pipeline-' + timestamp_prefix\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    Containers=[\n",
    "        {\n",
    "            'Image': sklearn_preprocessor.image_name,\n",
    "            'ModelDataUrl': sklearn_preprocessor.model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": str(sklearn_preprocessor.enable_cloudwatch_metrics),\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": sklearn_preprocessor.uploaded_code.s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"feature-transform\",\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": str(sklearn_preprocessor.container_log_level),\n",
    "                    \"SAGEMAKER_REGION\": sklearn_preprocessor.sagemaker_session.boto_region_name,\n",
    "                    \"SAGEMAKER_PROGRAM\": sklearn_preprocessor.uploaded_code.script_name\n",
    "                }\n",
    "        },\n",
    "        {\n",
    "            'Image': xgb.image_name,\n",
    "            'ModelDataUrl': xgb.model_data,\n",
    "            \"Environment\": {}\n",
    "        },\n",
    "        {\n",
    "            'Image': scikit_learn_post_process_model.image,\n",
    "            'ModelDataUrl': scikit_learn_post_process_model.model_data,\n",
    "            'Environment': {\n",
    "                    \"SAGEMAKER_ENABLE_CLOUDWATCH_METRICS\": str(sklearn_preprocessor.enable_cloudwatch_metrics),\n",
    "                    \"SAGEMAKER_SUBMIT_DIRECTORY\": sklearn_preprocessor.uploaded_code.s3_prefix,\n",
    "                    \"TRANSFORM_MODE\": \"inverse-label-transform\",\n",
    "                    \"SAGEMAKER_CONTAINER_LOG_LEVEL\": str(sklearn_preprocessor.container_log_level),\n",
    "                    \"SAGEMAKER_REGION\": sklearn_preprocessor.sagemaker_session.boto_region_name,\n",
    "                    \"SAGEMAKER_PROGRAM\": sklearn_preprocessor.uploaded_code.script_name\n",
    "                }\n",
    "        },\n",
    "    ],\n",
    "    ExecutionRoleArn = role,\n",
    ")\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 Inference Pipeline의 모델을 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference pipeline model name:\n",
      " churn-inference-pipeline-2020-07-19-02-04-24\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference pipeline model name:\\n {}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
