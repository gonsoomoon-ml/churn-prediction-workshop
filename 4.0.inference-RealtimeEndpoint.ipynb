{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 5] Make Realtime Endpoint and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- Endpoint Config 생성\n",
    "- RealTime Endpoint 생성\n",
    "- Predictor 생성\n",
    "- 추론 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "from time import strftime, gmtime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias #\n",
      "no stored variable or alias Load\n",
      "no stored variable or alias varibles\n",
      "no stored variable or alias stored\n"
     ]
    }
   ],
   "source": [
    "%store -r # Load varibles stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EndpointConfig 생성\n",
    "- Realtime Endpoint를 만들기 위한 설정 파일을 만듦니다.\n",
    "    - model_name은 기존에 만든 model을 사용합니다. 위의 %store -r을 통해서 해당 이름을 가져 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6c5791232018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         {\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m'VariantName'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"AllTraffic\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;34m'ModelName'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;34m'InitialInstanceCount'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m'InstanceType'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'ml.m4.xlarge'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "client = boto3.client(\"sagemaker\")\n",
    "endpoint_config_name = \"churn-inference-pipeline-\" + timestamp_prefix\n",
    "response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants = [\n",
    "        {\n",
    "            'VariantName' : \"AllTraffic\",\n",
    "            'ModelName' : model_name,\n",
    "            'InitialInstanceCount' : 1,\n",
    "            'InstanceType' : 'ml.m4.xlarge'\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_endpoint_name = 'churn-inference-pipeline-endpoint-' + timestamp_prefix\n",
    "churn_endpoint = client.create_endpoint(\n",
    "    EndpointName = churn_endpoint_name,\n",
    "    EndpointConfigName = endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EndpointStatus 가 InService**가 될때까지 기다려 주세요. 그렇지 않으면 아래 코드가 에러나 납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.describe_endpoint(EndpointName = churn_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predictor\n",
    "- 위에서 생성한 Endpoint에 CSV 형태의 입력 데이타를 받을 수 있게 csv_serializer를 지정 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint = churn_endpoint_name,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    serializer = csv_serializer,\n",
    "    content_type = CONTENT_TYPE_CSV,\n",
    "    accept = CONTENT_TYPE_JSON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 위한 입력 포맷을 만듦\n",
    "- 이런 형태로 입력이 됨 (에:)\n",
    "    - ' KS,186,510,400-6454,no,no,0,137.8,97,23.43,187.7,118,15.95,146.4,85,6.59,8.7,6,2.35,1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_inference_format(sample):\n",
    "    instance = str()\n",
    "    for i, token in enumerate(sample):\n",
    "        # print(token)\n",
    "        if i > 0:\n",
    "            instance = instance  + ',' + str(token) \n",
    "        else:\n",
    "            instance = instance  +  str(token) \n",
    "    return instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 데이타에서 10명을 추론\n",
    "- 10명 중에서 7번째 고객이 이탈이 가능하다고 결과를 냄. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"churn_data/batch_transform_test.csv\", header=None)\n",
    "\n",
    "for i in range(10):\n",
    "    sample = test_df.iloc[i,:]\n",
    "    instance = make_inference_format(sample)\n",
    "    print(\"instance: \\n\", instance)\n",
    "\n",
    "    payload = instance\n",
    "    churn_result = predictor.predict(payload)\n",
    "    print(\"Churn result?: \\n\", churn_result)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint\n",
    "- 작업을 완료 했으면, 필요 없는 리소스는 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_endpoint(EndpointName=churn_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
