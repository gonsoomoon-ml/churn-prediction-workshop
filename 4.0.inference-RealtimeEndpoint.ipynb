{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 4.0] Make Realtime Endpoint and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북은 아래와 같은 작업을 합니다.\n",
    "- Endpoint Config 생성\n",
    "- RealTime Endpoint 생성\n",
    "- Predictor 생성\n",
    "- 추론 실행\n",
    "\n",
    "소요시간은 약 10분 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "\n",
    "from time import strftime, gmtime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EndpointConfig 생성\n",
    "- Realtime Endpoint를 만들기 위한 설정 파일을 만듦니다.\n",
    "    - model_name은 기존에 만든 model을 사용합니다. 위의 %store -r을 통해서 해당 이름을 가져 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"sagemaker\")\n",
    "endpoint_config_name = \"churn-inference-pipeline-\" + timestamp_prefix\n",
    "response = client.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants = [\n",
    "        {\n",
    "            'VariantName' : \"AllTraffic\",\n",
    "            'ModelName' : model_name,\n",
    "            'InitialInstanceCount' : 1,\n",
    "            'InstanceType' : 'ml.m4.xlarge'\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_endpoint_name = 'churn-inference-pipeline-endpoint-' + timestamp_prefix\n",
    "churn_endpoint = client.create_endpoint(\n",
    "    EndpointName = churn_endpoint_name,\n",
    "    EndpointConfigName = endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EndpointStatus 가 InService**가 될때까지 기다려 주세요. 그렇지 않으면 아래 코드가 에러나 납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'churn-inference-pipeline-endpoint-2020-07-19-02-53-07',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:us-east-2:057716757052:endpoint/churn-inference-pipeline-endpoint-2020-07-19-02-53-07',\n",
       " 'EndpointConfigName': 'churn-inference-pipeline-2020-07-19-02-53-07',\n",
       " 'EndpointStatus': 'Creating',\n",
       " 'CreationTime': datetime.datetime(2020, 7, 19, 2, 53, 8, 6000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 7, 19, 2, 53, 8, 6000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'f1a52d7e-3fdd-40e5-8b7a-6ba956fcc64e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f1a52d7e-3fdd-40e5-8b7a-6ba956fcc64e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '356',\n",
       "   'date': 'Sun, 19 Jul 2020 02:53:07 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_endpoint(EndpointName = churn_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Predictor\n",
    "- 위에서 생성한 Endpoint에 CSV 형태의 입력 데이타를 받을 수 있게 csv_serializer를 지정 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint = churn_endpoint_name,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    serializer = csv_serializer,\n",
    "    content_type = CONTENT_TYPE_CSV,\n",
    "    accept = CONTENT_TYPE_JSON\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 위한 입력 포맷을 만듦\n",
    "- 이런 형태로 입력이 됨 (에:)\n",
    "    - ' KS,186,510,400-6454,no,no,0,137.8,97,23.43,187.7,118,15.95,146.4,85,6.59,8.7,6,2.35,1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_inference_format(sample):\n",
    "    instance = str()\n",
    "    for i, token in enumerate(sample):\n",
    "        # print(token)\n",
    "        if i > 0:\n",
    "            instance = instance  + ',' + str(token) \n",
    "        else:\n",
    "            instance = instance  +  str(token) \n",
    "    return instance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 데이타에서 10명을 추론\n",
    "- 10명 중에서 7번째 고객이 이탈이 가능하다고 결과를 냄. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance: \n",
      " KS,186,510,400-6454,no,no,0,137.8,97,23.43,187.7,118,15.95,146.4,85,6.59,8.7,6,2.35,1\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " MA,132,415,343-5372,no,yes,25,113.2,96,19.24,269.9,107,22.94,229.1,87,10.31,7.1,7,1.92,2\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " MA,112,415,358-7379,no,yes,17,183.2,95,31.14,252.8,125,21.49,156.7,95,7.05,9.7,3,2.62,0\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " FL,91,510,387-9855,yes,yes,24,93.5,112,15.9,183.4,128,15.59,240.7,133,10.83,9.9,3,2.67,0\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " SC,22,408,331-5138,no,no,0,110.3,107,18.75,166.5,93,14.15,202.3,96,9.1,9.5,5,2.57,0\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " DC,102,415,402-9704,no,no,0,186.8,92,31.76,173.7,123,14.76,250.9,131,11.29,9.7,4,2.62,2\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " ME,118,408,384-8723,yes,yes,21,156.5,122,26.61,209.2,125,17.78,158.7,81,7.14,11.1,3,3.0,4\n",
      "Churn result?: \n",
      " b'True\\n'\n",
      "\n",
      "instance: \n",
      " NM,178,415,398-1332,no,yes,35,175.4,88,29.82,190.0,65,16.15,138.7,94,6.24,10.5,3,2.84,2\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " NV,107,510,419-9688,yes,no,0,234.1,91,39.8,163.1,105,13.86,282.5,100,12.71,10.0,3,2.7,1\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n",
      "instance: \n",
      " WY,94,408,344-4022,no,no,0,207.0,109,35.19,167.4,80,14.23,238.2,117,10.72,2.6,6,0.7,1\n",
      "Churn result?: \n",
      " b'False\\n'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"churn_data/batch_transform_test.csv\", header=None)\n",
    "\n",
    "for i in range(10):\n",
    "    sample = test_df.iloc[i,:]\n",
    "    instance = make_inference_format(sample)\n",
    "    print(\"instance: \\n\", instance)\n",
    "\n",
    "    payload = instance\n",
    "    churn_result = predictor.predict(payload)\n",
    "    print(\"Churn result?: \\n\", churn_result)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint\n",
    "- 작업을 완료 했으면, 필요 없는 리소스는 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'a0ae2cca-6069-4cc1-acb1-46cf0309ce87',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'a0ae2cca-6069-4cc1-acb1-46cf0309ce87',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Sun, 19 Jul 2020 03:15:08 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_endpoint(EndpointName=churn_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
